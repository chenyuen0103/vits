Fine-tuning ViT-S_16 on waterbirdsTraining parameters Namespace(name='waterbirds_hessian', dataset='waterbirds', model_arch='ViT', model_type='ViT-S_16', output_dir='output', img_size=384, train_batch_size=512, eval_batch_size=64, eval_every=100, learning_rate=0.03, weight_decay=0, num_steps=700, warmup_steps=100, max_grad_norm=1.0, local_rank=-1, seed=0, batch_split=16, hessian_align=False, grad_alpha=0.0, hess_beta=0.0, resume=False, n_gpu=4, device=device(type='cuda'))Total Parameter: 	21.8MName: waterbirds_hessian
Dataset: waterbirds
Model arch: ViT
Model type: ViT-S_16
Output dir: output
Img size: 384
Train batch size: 32
Eval batch size: 64
Eval every: 100
Learning rate: 0.03
Weight decay: 0
Num steps: 700
Warmup steps: 100
Max grad norm: 1.0
Local rank: -1
Seed: 0
Batch split: 16
Hessian align: False
Grad alpha: 0.0
Hess beta: 0.0
Resume: False
N gpu: 4
Device: cuda

***** Running training *****  Total optimization steps = 700  Instantaneous batch size per GPU = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Total train batch size (w. parallel, distributed & accumulation) = 32  Gradient Accumulation steps = 16Step: 1 	Average incurred loss: 1.630  
Average sample loss: 1.630  
Hessian aligned loss: 0.000  
Average acc: 0.232  
group = 0[n = 373]:	loss = 1.757  exp loss = 1.791  adjusted loss = 1.791  adv prob = 0.250000   acc = 0.204
grad norm = 0.194
hessian norm = 0.194
group = 1[n = 19]:	loss = 1.598  exp loss = 1.384  adjusted loss = 1.384  adv prob = 0.250000   acc = 0.316
grad norm = 0.283
hessian norm = 0.283
group = 2[n = 11]:	loss = 0.712  exp loss = 0.763  adjusted loss = 0.763  adv prob = 0.250000   acc = 0.455
grad norm = 0.455
hessian norm = 0.455
group = 3[n = 109]:	loss = 1.295  exp loss = 1.265  adjusted loss = 1.265  adv prob = 0.250000   acc = 0.294
grad norm = 0.261
hessian norm = 0.261
Step: 2 	Average incurred loss: 1.520  
Average sample loss: 1.520  
Hessian aligned loss: 0.000  
Average acc: 0.240  
group = 0[n = 381]:	loss = 1.675  exp loss = 1.730  adjusted loss = 1.730  adv prob = 0.250000   acc = 0.192
grad norm = 0.181
hessian norm = 0.181
group = 1[n = 16]:	loss = 1.223  exp loss = 1.149  adjusted loss = 1.149  adv prob = 0.250000   acc = 0.375
grad norm = 0.352
hessian norm = 0.352
group = 2[n = 8]:	loss = 0.783  exp loss = 0.813  adjusted loss = 0.813  adv prob = 0.250000   acc = 0.500
grad norm = 0.500
hessian norm = 0.500
group = 3[n = 107]:	loss = 1.067  exp loss = 1.135  adjusted loss = 1.135  adv prob = 0.250000   acc = 0.374
grad norm = 0.342
hessian norm = 0.342
Step: 3 	Average incurred loss: 1.506  
Average sample loss: 1.506  
Hessian aligned loss: 0.000  
Average acc: 0.275  
group = 0[n = 378]:	loss = 1.664  exp loss = 1.674  adjusted loss = 1.674  adv prob = 0.250000   acc = 0.241
grad norm = 0.228
hessian norm = 0.228
group = 1[n = 17]:	loss = 1.128  exp loss = 1.230  adjusted loss = 1.230  adv prob = 0.250000   acc = 0.294
grad norm = 0.277
hessian norm = 0.277
group = 2[n = 3]:	loss = 0.758  exp loss = 0.803  adjusted loss = 0.803  adv prob = 0.250000   acc = 0.667
grad norm = 0.444
hessian norm = 0.444
group = 3[n = 114]:	loss = 1.058  exp loss = 1.105  adjusted loss = 1.105  adv prob = 0.250000   acc = 0.377
grad norm = 0.344
hessian norm = 0.344
Step: 4 	Average incurred loss: 1.487  
Average sample loss: 1.487  
Hessian aligned loss: 0.000  
Average acc: 0.291  
group = 0[n = 383]:	loss = 1.557  exp loss = 1.556  adjusted loss = 1.556  adv prob = 0.250000   acc = 0.282
grad norm = 0.267
hessian norm = 0.267
group = 1[n = 20]:	loss = 1.492  exp loss = 1.412  adjusted loss = 1.412  adv prob = 0.250000   acc = 0.250
grad norm = 0.213
hessian norm = 0.213
group = 2[n = 5]:	loss = 0.714  exp loss = 0.759  adjusted loss = 0.759  adv prob = 0.250000   acc = 0.400
grad norm = 0.320
hessian norm = 0.320
group = 3[n = 104]:	loss = 1.265  exp loss = 1.229  adjusted loss = 1.229  adv prob = 0.250000   acc = 0.327
grad norm = 0.302
hessian norm = 0.302
Step: 5 	Average incurred loss: 1.383  
Average sample loss: 1.383  
Hessian aligned loss: 0.000  
Average acc: 0.328  
group = 0[n = 360]:	loss = 1.449  exp loss = 1.493  adjusted loss = 1.493  adv prob = 0.250000   acc = 0.300
grad norm = 0.284
hessian norm = 0.284
group = 1[n = 25]:	loss = 1.284  exp loss = 1.223  adjusted loss = 1.223  adv prob = 0.250000   acc = 0.400
grad norm = 0.384
hessian norm = 0.384
group = 2[n = 8]:	loss = 0.800  exp loss = 0.809  adjusted loss = 0.809  adv prob = 0.250000   acc = 0.625
grad norm = 0.547
hessian norm = 0.547
group = 3[n = 119]:	loss = 1.243  exp loss = 1.224  adjusted loss = 1.224  adv prob = 0.250000   acc = 0.378
grad norm = 0.343
hessian norm = 0.343
Step: 6 	Average incurred loss: 1.275  
Average sample loss: 1.275  
Hessian aligned loss: 0.000  
Average acc: 0.336  
group = 0[n = 378]:	loss = 1.246  exp loss = 1.312  adjusted loss = 1.312  adv prob = 0.250000   acc = 0.347
grad norm = 0.325
hessian norm = 0.325
group = 1[n = 22]:	loss = 1.100  exp loss = 1.066  adjusted loss = 1.066  adv prob = 0.250000   acc = 0.318
grad norm = 0.260
hessian norm = 0.260
group = 2[n = 5]:	loss = 0.884  exp loss = 0.829  adjusted loss = 0.829  adv prob = 0.250000   acc = 0.600
grad norm = 0.600
hessian norm = 0.600
group = 3[n = 107]:	loss = 1.430  exp loss = 1.416  adjusted loss = 1.416  adv prob = 0.250000   acc = 0.290
grad norm = 0.276
hessian norm = 0.276
Step: 7 	Average incurred loss: 1.158  
Average sample loss: 1.158  
Hessian aligned loss: 0.000  
Average acc: 0.393  
group = 0[n = 384]:	loss = 0.986  exp loss = 1.014  adjusted loss = 1.014  adv prob = 0.250000   acc = 0.456
grad norm = 0.431
hessian norm = 0.431
group = 1[n = 19]:	loss = 0.996  exp loss = 0.994  adjusted loss = 0.994  adv prob = 0.250000   acc = 0.421
grad norm = 0.377
hessian norm = 0.377
group = 2[n = 4]:	loss = 1.952  exp loss = 1.237  adjusted loss = 1.237  adv prob = 0.250000   acc = 0.000
grad norm = 0.000
hessian norm = 0.000
group = 3[n = 105]:	loss = 1.783  exp loss = 1.606  adjusted loss = 1.606  adv prob = 0.250000   acc = 0.171
grad norm = 0.157
hessian norm = 0.157
Step: 8 	Average incurred loss: 0.895  
Average sample loss: 0.895  
Hessian aligned loss: 0.000  
Average acc: 0.557  
group = 0[n = 375]:	loss = 0.647  exp loss = 0.709  adjusted loss = 0.709  adv prob = 0.250000   acc = 0.675
grad norm = 0.631
hessian norm = 0.631
group = 1[n = 20]:	loss = 0.542  exp loss = 0.684  adjusted loss = 0.684  adv prob = 0.250000   acc = 0.700
grad norm = 0.700
hessian norm = 0.700
group = 2[n = 2]:	loss = 1.281  exp loss = 1.248  adjusted loss = 1.248  adv prob = 0.250000   acc = 0.000
grad norm = 0.000
hessian norm = 0.000
group = 3[n = 115]:	loss = 1.758  exp loss = 1.727  adjusted loss = 1.727  adv prob = 0.250000   acc = 0.157
grad norm = 0.147
hessian norm = 0.147
Step: 9 	Average incurred loss: 0.914  
Average sample loss: 0.914  
Hessian aligned loss: 0.000  
Average acc: 0.598  
group = 0[n = 354]:	loss = 0.462  exp loss = 0.520  adjusted loss = 0.520  adv prob = 0.250000   acc = 0.768
grad norm = 0.714
hessian norm = 0.714
group = 1[n = 18]:	loss = 0.678  exp loss = 0.712  adjusted loss = 0.712  adv prob = 0.250000   acc = 0.722
grad norm = 0.722
hessian norm = 0.722
group = 2[n = 8]:	loss = 2.978  exp loss = 2.112  adjusted loss = 2.112  adv prob = 0.250000   acc = 0.000
grad norm = 0.000
hessian norm = 0.000
group = 3[n = 132]:	loss = 2.032  exp loss = 2.007  adjusted loss = 2.007  adv prob = 0.250000   acc = 0.159
grad norm = 0.151
hessian norm = 0.151
Step: 10 	Average incurred loss: 0.731  
Average sample loss: 0.731  
Hessian aligned loss: 0.000  
Average acc: 0.712  
group = 0[n = 513]:	loss = 0.258  exp loss = 0.295  adjusted loss = 0.295  adv prob = 0.250000   acc = 0.912
grad norm = 0.870
hessian norm = 0.870
group = 1[n = 22]:	loss = 0.343  exp loss = 0.415  adjusted loss = 0.415  adv prob = 0.250000   acc = 0.818
grad norm = 0.781
hessian norm = 0.781
group = 2[n = 7]:	loss = 3.433  exp loss = 2.766  adjusted loss = 2.766  adv prob = 0.250000   acc = 0.000
grad norm = 0.000
hessian norm = 0.000
group = 3[n = 157]:	loss = 2.209  exp loss = 2.242  adjusted loss = 2.242  adv prob = 0.250000   acc = 0.076
grad norm = 0.074
hessian norm = 0.074
Step: 11 	Average incurred loss: 0.633  
Average sample loss: 0.633  
Hessian aligned loss: 0.000  
Average acc: 0.760  
group = 0[n = 381]:	loss = 0.143  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.955
grad norm = 0.903
hessian norm = 0.903
group = 1[n = 20]:	loss = 0.286  exp loss = 0.316  adjusted loss = 0.316  adv prob = 0.250000   acc = 0.850
grad norm = 0.765
hessian norm = 0.765
group = 2[n = 8]:	loss = 2.520  exp loss = 2.648  adjusted loss = 2.648  adv prob = 0.250000   acc = 0.000
grad norm = 0.000
hessian norm = 0.000
group = 3[n = 103]:	loss = 2.366  exp loss = 2.382  adjusted loss = 2.382  adv prob = 0.250000   acc = 0.078
grad norm = 0.071
hessian norm = 0.071
Step: 12 	Average incurred loss: 0.643  
Average sample loss: 0.643  
Hessian aligned loss: 0.000  
Average acc: 0.758  
group = 0[n = 374]:	loss = 0.124  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.960
grad norm = 0.898
hessian norm = 0.898
group = 1[n = 18]:	loss = 0.275  exp loss = 0.306  adjusted loss = 0.306  adv prob = 0.250000   acc = 0.944
grad norm = 0.944
hessian norm = 0.944
group = 2[n = 5]:	loss = 3.634  exp loss = 3.005  adjusted loss = 3.005  adv prob = 0.250000   acc = 0.000
grad norm = 0.000
hessian norm = 0.000
group = 3[n = 115]:	loss = 2.261  exp loss = 2.232  adjusted loss = 2.232  adv prob = 0.250000   acc = 0.104
grad norm = 0.097
hessian norm = 0.097
Step: 13 	Average incurred loss: 0.564  
Average sample loss: 0.564  
Hessian aligned loss: 0.000  
Average acc: 0.779  
group = 0[n = 374]:	loss = 0.104  exp loss = 0.106  adjusted loss = 0.106  adv prob = 0.250000   acc = 0.968
grad norm = 0.908
hessian norm = 0.908
group = 1[n = 25]:	loss = 0.281  exp loss = 0.259  adjusted loss = 0.259  adv prob = 0.250000   acc = 0.920
grad norm = 0.846
hessian norm = 0.846
group = 2[n = 3]:	loss = 3.396  exp loss = 3.102  adjusted loss = 3.102  adv prob = 0.250000   acc = 0.000
grad norm = 0.000
hessian norm = 0.000
group = 3[n = 110]:	loss = 2.114  exp loss = 2.152  adjusted loss = 2.152  adv prob = 0.250000   acc = 0.127
grad norm = 0.119
hessian norm = 0.119
Step: 14 	Average incurred loss: 0.611  
Average sample loss: 0.611  
Hessian aligned loss: 0.000  
Average acc: 0.762  
group = 0[n = 358]:	loss = 0.071  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 0.980
grad norm = 0.920
hessian norm = 0.920
group = 1[n = 19]:	loss = 0.332  exp loss = 0.344  adjusted loss = 0.344  adv prob = 0.250000   acc = 0.947
grad norm = 0.848
hessian norm = 0.848
group = 2[n = 11]:	loss = 4.542  exp loss = 3.991  adjusted loss = 3.991  adv prob = 0.250000   acc = 0.000
grad norm = 0.000
hessian norm = 0.000
group = 3[n = 124]:	loss = 1.863  exp loss = 1.985  adjusted loss = 1.985  adv prob = 0.250000   acc = 0.169
grad norm = 0.158
hessian norm = 0.158
Step: 15 	Average incurred loss: 0.377  
Average sample loss: 0.377  
Hessian aligned loss: 0.000  
Average acc: 0.854  
group = 0[n = 396]:	loss = 0.075  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 0.982
grad norm = 0.920
hessian norm = 0.920
group = 1[n = 21]:	loss = 0.367  exp loss = 0.456  adjusted loss = 0.456  adv prob = 0.250000   acc = 0.905
grad norm = 0.905
hessian norm = 0.905
group = 2[n = 5]:	loss = 4.800  exp loss = 4.306  adjusted loss = 4.306  adv prob = 0.250000   acc = 0.000
grad norm = 0.000
hessian norm = 0.000
group = 3[n = 90]:	loss = 1.460  exp loss = 1.551  adjusted loss = 1.551  adv prob = 0.250000   acc = 0.322
grad norm = 0.301
hessian norm = 0.301
Step: 16 	Average incurred loss: 0.367  
Average sample loss: 0.367  
Hessian aligned loss: 0.000  
Average acc: 0.816  
group = 0[n = 360]:	loss = 0.093  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 0.981
grad norm = 0.912
hessian norm = 0.912
group = 1[n = 20]:	loss = 0.526  exp loss = 0.508  adjusted loss = 0.508  adv prob = 0.250000   acc = 0.650
grad norm = 0.617
hessian norm = 0.617
group = 2[n = 4]:	loss = 4.595  exp loss = 4.377  adjusted loss = 4.377  adv prob = 0.250000   acc = 0.000
grad norm = 0.000
hessian norm = 0.000
group = 3[n = 128]:	loss = 0.982  exp loss = 1.027  adjusted loss = 1.027  adv prob = 0.250000   acc = 0.406
grad norm = 0.390
hessian norm = 0.390
Step: 17 	Average incurred loss: 0.296  
Average sample loss: 0.296  
Hessian aligned loss: 0.000  
Average acc: 0.885  
group = 0[n = 383]:	loss = 0.123  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 0.963
grad norm = 0.893
hessian norm = 0.893
group = 1[n = 22]:	loss = 0.956  exp loss = 0.743  adjusted loss = 0.743  adv prob = 0.250000   acc = 0.545
grad norm = 0.545
hessian norm = 0.545
group = 2[n = 8]:	loss = 1.717  exp loss = 3.276  adjusted loss = 3.276  adv prob = 0.250000   acc = 0.375
grad norm = 0.375
hessian norm = 0.375
group = 3[n = 99]:	loss = 0.705  exp loss = 0.745  adjusted loss = 0.745  adv prob = 0.250000   acc = 0.697
grad norm = 0.669
hessian norm = 0.669
Step: 18 	Average incurred loss: 0.325  
Average sample loss: 0.325  
Hessian aligned loss: 0.000  
Average acc: 0.861  
group = 0[n = 360]:	loss = 0.204  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.919
grad norm = 0.853
hessian norm = 0.853
group = 1[n = 22]:	loss = 1.251  exp loss = 1.330  adjusted loss = 1.330  adv prob = 0.250000   acc = 0.273
grad norm = 0.248
hessian norm = 0.248
group = 2[n = 4]:	loss = 1.176  exp loss = 2.594  adjusted loss = 2.594  adv prob = 0.250000   acc = 0.500
grad norm = 0.500
hessian norm = 0.500
group = 3[n = 126]:	loss = 0.481  exp loss = 0.509  adjusted loss = 0.509  adv prob = 0.250000   acc = 0.810
grad norm = 0.784
hessian norm = 0.784
Step: 19 	Average incurred loss: 0.292  
Average sample loss: 0.293  
Hessian aligned loss: 0.000  
Average acc: 0.896  
group = 0[n = 510]:	loss = 0.179  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.931
grad norm = 0.882
hessian norm = 0.882
group = 1[n = 19]:	loss = 1.842  exp loss = 1.756  adjusted loss = 1.756  adv prob = 0.250000   acc = 0.211
grad norm = 0.211
hessian norm = 0.211
group = 2[n = 8]:	loss = 1.755  exp loss = 2.070  adjusted loss = 2.070  adv prob = 0.250000   acc = 0.375
grad norm = 0.328
hessian norm = 0.328
group = 3[n = 162]:	loss = 0.394  exp loss = 0.447  adjusted loss = 0.447  adv prob = 0.250000   acc = 0.889
grad norm = 0.867
hessian norm = 0.867
